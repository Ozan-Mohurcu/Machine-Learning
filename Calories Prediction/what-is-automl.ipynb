{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75059aa",
   "metadata": {
    "papermill": {
     "duration": 0.005265,
     "end_time": "2025-05-28T15:16:50.187288",
     "exception": false,
     "start_time": "2025-05-28T15:16:50.182023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info alert-warning\" style=\"background-color: white; color: black; text-align: center;\">\n",
    "    <h1><span style=\"color: red;\">Ozan M√ñH√úRC√ú</span></h1>\n",
    "    <h1><span style=\"color: red;\">Data Analyst | Data Scientist</span></h1>\n",
    "\n",
    " <div style=\"text-align: center; font-family: Arial, sans-serif; margin-top: 20px;\">\n",
    "        <a href=\"https://www.linkedin.com/in/ozanmhrc/\" style=\"text-decoration: none; color: #fff; margin-right: 10px;\">\n",
    "            <span style=\"background-color: #0077B5; padding: 8px 20px; border-radius: 5px; font-size: 14px; display: inline-block; width: 120px; text-align: center;\">LinkedIn</span>\n",
    "        </a>\n",
    "        <a href=\"https://github.com/Ozan-Mohurcu\" style=\"text-decoration: none; color: #fff; margin-right: 10px;\">\n",
    "            <span style=\"background-color: #333; padding: 8px 20px; border-radius: 5px; font-size: 14px; display: inline-block; width: 120px; text-align: center;\">GitHub</span>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4470efe",
   "metadata": {
    "papermill": {
     "duration": 0.00396,
     "end_time": "2025-05-28T15:16:50.195692",
     "exception": false,
     "start_time": "2025-05-28T15:16:50.191732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">What is AutoML</h2>\n",
    "  <p>\n",
    "      \n",
    " - AutoML (Automated Machine Learning) is a technology that enables the automatic creation, training, and optimization of machine learning models without human intervention.\n",
    "      \n",
    "- It automates tasks such as data preprocessing, model selection, and hyperparameter tuning, allowing even non-expert users to build effective models.\n",
    "    AutoML is especially useful for saving time and reducing the need for deep machine learning expertise.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa225ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T12:25:36.766683Z",
     "iopub.status.busy": "2025-05-28T12:25:36.766333Z",
     "iopub.status.idle": "2025-05-28T12:25:36.779335Z",
     "shell.execute_reply": "2025-05-28T12:25:36.777328Z",
     "shell.execute_reply.started": "2025-05-28T12:25:36.766656Z"
    },
    "papermill": {
     "duration": 0.003794,
     "end_time": "2025-05-28T15:16:50.203754",
     "exception": false,
     "start_time": "2025-05-28T15:16:50.199960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Libraries Import</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e726a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:16:50.214667Z",
     "iopub.status.busy": "2025-05-28T15:16:50.213776Z",
     "iopub.status.idle": "2025-05-28T15:17:28.300453Z",
     "shell.execute_reply": "2025-05-28T15:17:28.299467Z"
    },
    "papermill": {
     "duration": 38.09403,
     "end_time": "2025-05-28T15:17:28.302398",
     "exception": false,
     "start_time": "2025-05-28T15:16:50.208368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install flaml \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a53092",
   "metadata": {
    "papermill": {
     "duration": 0.004032,
     "end_time": "2025-05-28T15:17:28.310998",
     "exception": false,
     "start_time": "2025-05-28T15:17:28.306966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Data Loading</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31230f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:17:28.321183Z",
     "iopub.status.busy": "2025-05-28T15:17:28.320457Z",
     "iopub.status.idle": "2025-05-28T15:17:29.595101Z",
     "shell.execute_reply": "2025-05-28T15:17:29.594064Z"
    },
    "papermill": {
     "duration": 1.281662,
     "end_time": "2025-05-28T15:17:29.596901",
     "exception": false,
     "start_time": "2025-05-28T15:17:28.315239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e5/test.csv', index_col='id')\n",
    "sub = pd.read_csv('/kaggle/input/playground-series-s5e5/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55795c",
   "metadata": {
    "papermill": {
     "duration": 0.004701,
     "end_time": "2025-05-28T15:17:29.611562",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.606861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Feature Engineering</h2>\n",
    "  <p>\n",
    "      \n",
    "- Feature Engineering is the process of creating meaningful input features from raw data to improve the performance of machine learning models.  \n",
    "- It involves transforming, selecting, or generating new features.  \n",
    "- Good feature engineering can significantly enhance model accuracy and efficiency.  \n",
    "- Even simple models can perform well with well-crafted features.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb05798d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:17:29.622487Z",
     "iopub.status.busy": "2025-05-28T15:17:29.621760Z",
     "iopub.status.idle": "2025-05-28T15:17:29.922206Z",
     "shell.execute_reply": "2025-05-28T15:17:29.921176Z"
    },
    "papermill": {
     "duration": 0.307738,
     "end_time": "2025-05-28T15:17:29.923978",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.616240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)\n",
    "    df['Body_Temp_Duration'] = df['Body_Temp'] * df['Duration']\n",
    "    df['Weight_Heart_Rate'] = df['Weight'] * df['Heart_Rate']\n",
    "    df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_fe = feature_engineering(train)\n",
    "test_fe = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f60a07",
   "metadata": {
    "papermill": {
     "duration": 0.00404,
     "end_time": "2025-05-28T15:17:29.932634",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.928594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Understanding the Code: Data Preparation</h2>\n",
    "  <p>\n",
    "    1. <strong>X_train = train_fe.drop(columns='Calories')</strong> creates the feature matrix by removing the target column 'Calories' from the dataset.<br>\n",
    "    2. <strong>y_train = np.log1p(train_fe['Calories'])</strong> transforms the target variable by applying the natural logarithm plus one, which helps in stabilizing variance and handling skewness.<br>\n",
    "    3. This process prepares the data for training machine learning models by separating input features (X_train) and the transformed target variable (y_train).\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842944cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:17:29.942762Z",
     "iopub.status.busy": "2025-05-28T15:17:29.942422Z",
     "iopub.status.idle": "2025-05-28T15:17:29.976074Z",
     "shell.execute_reply": "2025-05-28T15:17:29.974995Z"
    },
    "papermill": {
     "duration": 0.040913,
     "end_time": "2025-05-28T15:17:29.977876",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.936963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_fe.drop(columns='Calories')\n",
    "y_train = np.log1p(train_fe['Calories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54dcb5",
   "metadata": {
    "papermill": {
     "duration": 0.004006,
     "end_time": "2025-05-28T15:17:29.987049",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.983043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Using AutoML for Regression</h2>\n",
    "  <p>\n",
    "    1. <strong>aml = AutoML()</strong> creates a new AutoML instance to automate the machine learning workflow.<br>\n",
    "    2. The <strong>fit()</strong> method trains the model using <code>X_train</code> as input features and <code>y_train</code> as the target variable.<br>\n",
    "    3. The <strong>task='regression'</strong> parameter specifies that the model is solving a regression problem.<br>\n",
    "    4. <strong>metric='rmse'</strong> sets Root Mean Squared Error as the evaluation metric to measure prediction accuracy.<br>\n",
    "    5. <strong>time_budget=3600</strong> limits the training process to one hour to manage computational resources.<br>\n",
    "    6. <strong>eval_method='cv'</strong> and <strong>n_splits=5</strong> enable 5-fold cross-validation for more robust model evaluation.<br>\n",
    "    7. <strong>estimator_list=['xgboost', 'lgbm', 'catboost']</strong> restricts the search to these three popular gradient boosting algorithms.<br>\n",
    "    8. <strong>ensemble=True</strong> allows combining multiple models to improve overall prediction performance.<br>\n",
    "    9. <strong>verbose=3</strong> provides detailed output during training, useful for monitoring progress.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62249811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:17:29.996792Z",
     "iopub.status.busy": "2025-05-28T15:17:29.996462Z",
     "iopub.status.idle": "2025-05-28T16:32:43.892496Z",
     "shell.execute_reply": "2025-05-28T16:32:43.891479Z"
    },
    "papermill": {
     "duration": 4513.903373,
     "end_time": "2025-05-28T16:32:43.894530",
     "exception": false,
     "start_time": "2025-05-28T15:17:29.991157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aml = AutoML()\n",
    "aml.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    task='regression',\n",
    "    metric='rmse',  \n",
    "    time_budget=3600, # 1 Hour\n",
    "    eval_method='cv',\n",
    "    n_splits=5,\n",
    "    estimator_list=['xgboost', 'lgbm', 'catboost'], \n",
    "    ensemble=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1b007",
   "metadata": {
    "papermill": {
     "duration": 0.00408,
     "end_time": "2025-05-28T16:32:43.904632",
     "exception": false,
     "start_time": "2025-05-28T16:32:43.900552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">AutoML Results Summary</h2>\n",
    "  <p>\n",
    "    1. <strong>aml.best_estimator</strong> displays the name of the best-performing model found during the AutoML process.<br>\n",
    "    2. <strong>aml.best_config</strong> and <strong>aml.best_loss</strong> provide the optimal hyperparameters and the lowest validation loss achieved, respectively.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d89c895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:32:43.915379Z",
     "iopub.status.busy": "2025-05-28T16:32:43.914354Z",
     "iopub.status.idle": "2025-05-28T16:32:43.920488Z",
     "shell.execute_reply": "2025-05-28T16:32:43.919380Z"
    },
    "papermill": {
     "duration": 0.01314,
     "end_time": "2025-05-28T16:32:43.922116",
     "exception": false,
     "start_time": "2025-05-28T16:32:43.908976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model: catboost\n",
      "Best configuration: {'early_stopping_rounds': 11, 'learning_rate': 0.005, 'n_estimators': 8192}\n",
      "Best validation loss: 0.060354510942818615\n"
     ]
    }
   ],
   "source": [
    "print(\"The best model:\", aml.best_estimator)\n",
    "print(\"Best configuration:\", aml.best_config)\n",
    "print(\"Best validation loss:\", aml.best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01cf1",
   "metadata": {
    "papermill": {
     "duration": 0.004194,
     "end_time": "2025-05-28T16:32:43.931024",
     "exception": false,
     "start_time": "2025-05-28T16:32:43.926830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Data Preparation and Model Training Pipeline</h2>\n",
    "  <p>\n",
    "    1. The <strong>feature_engineering()</strong> function creates new meaningful features such as BMI, Body_Temp_Duration, and Weight_Heart_Rate, and applies one-hot encoding to the 'Sex' column.<br>\n",
    "    2. The target variable 'Calories' is log-transformed using <code>np.log1p</code> to stabilize variance and reduce skewness.<br>\n",
    "    3. Numerical and categorical columns are identified for preprocessing, where numerical features are standardized and categorical features are one-hot encoded.<br>\n",
    "    4. A pipeline is created that combines preprocessing steps with the LightGBM regression model, configured with specific hyperparameters.<br>\n",
    "    5. A 5-fold cross-validation strategy is implemented using <code>KFold</code> to split data into training and validation sets.<br>\n",
    "    6. For each fold, the model is trained and predictions are collected to compute out-of-fold predictions.<br>\n",
    "    7. Finally, the predictions are transformed back from the log scale, clipped to a reasonable range, and evaluated using the RMSLE metric to measure model accuracy.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa15a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:32:43.941467Z",
     "iopub.status.busy": "2025-05-28T16:32:43.941140Z",
     "iopub.status.idle": "2025-05-28T16:36:49.111271Z",
     "shell.execute_reply": "2025-05-28T16:36:49.110241Z"
    },
    "papermill": {
     "duration": 245.182303,
     "end_time": "2025-05-28T16:36:49.117692",
     "exception": false,
     "start_time": "2025-05-28T16:32:43.935389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data columns: ['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n",
      "Columns after feature engineering: ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories', 'BMI', 'Body_Temp_Duration', 'Weight_Heart_Rate', 'Sex_male']\n",
      "Numeric columns: ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Body_Temp_Duration', 'Weight_Heart_Rate']\n",
      "Categorical columns: ['Sex_male']\n",
      "Fold 1/5\n",
      "Fold 2/5\n",
      "Fold 3/5\n",
      "Fold 4/5\n",
      "Fold 5/5\n",
      "Validation RMSLE: 0.059882\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"Train data columns:\", train.columns.tolist())\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    # BMI\n",
    "    if 'Weight' in df.columns and 'Height' in df.columns:\n",
    "        df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)\n",
    "    else:\n",
    "        print(\"Error: Body_Temp or Duration column is missing!\")\n",
    "        df['BMI'] = 0\n",
    "    # Body_Temp_Duration\n",
    "    if 'Body_Temp' in df.columns and 'Duration' in df.columns:\n",
    "        df['Body_Temp_Duration'] = df['Body_Temp'] * df['Duration']\n",
    "    else:\n",
    "        print(\"Error: Body_Temp or Duration column is missing!\")\n",
    "        df['Body_Temp_Duration'] = 0\n",
    "    # Weight_Heart_Rate\n",
    "    if 'Weight' in df.columns and 'Heart_Rate' in df.columns:\n",
    "        df['Weight_Heart_Rate'] = df['Weight'] * df['Heart_Rate']\n",
    "    else:\n",
    "        print(\"Error: Weight or Heart_Rate column is missing!\")\n",
    "        df['Weight_Heart_Rate'] = 0\n",
    "    # Sex i√ßin one-hot encoding\n",
    "    if 'Sex' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['Sex'], drop_first=True, dummy_na=False)\n",
    "    else:\n",
    "        print(\"Error: Sex column is missing!\")\n",
    "        df['Sex_male'] = 0\n",
    "    return df\n",
    "\n",
    "\n",
    "train_fe = feature_engineering(train)\n",
    "print(\"Columns after feature engineering:\", train_fe.columns.tolist())\n",
    "\n",
    "\n",
    "if 'Calories' in train_fe.columns:\n",
    "    X_train = train_fe.drop(columns='Calories')\n",
    "    y_train = np.log1p(train_fe['Calories'])\n",
    "else:\n",
    "    raise ValueError(\"Error: Calories column missing in train_fe!\")\n",
    "\n",
    "\n",
    "numerical_cols = [col for col in ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', \n",
    "                                  'BMI', 'Body_Temp_Duration', 'Weight_Heart_Rate'] if col in X_train.columns]\n",
    "categorical_cols = [col for col in ['Sex_male'] if col in X_train.columns]\n",
    "print(\"Numeric columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "lgbm_params = {\n",
    "    'n_estimators': 1125,\n",
    "    'num_leaves': 110,\n",
    "    'min_child_samples': 9,\n",
    "    'learning_rate': 0.0179455702408711,\n",
    "    'colsample_bytree': 0.5979737441060009,\n",
    "    'reg_alpha': 0.001975258376030875,\n",
    "    'reg_lambda': 0.005106256873241264,\n",
    "    'max_bin': 2**10,  # log_max_bin=10\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**lgbm_params))\n",
    "])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Fold {fold+1}/5\")\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    oof_preds[val_idx] = pipeline.predict(X_val_fold)\n",
    "\n",
    "# Validasyon RMSLE\n",
    "y_pred_orig = np.expm1(oof_preds)\n",
    "y_pred_orig = np.clip(y_pred_orig, a_min=0, a_max=400)\n",
    "rmsle = np.sqrt(mean_squared_log_error(train['Calories'], y_pred_orig))\n",
    "print(f\"Validation RMSLE: {rmsle:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096cb76",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-28T12:44:21.365184Z",
     "iopub.status.idle": "2025-05-28T12:44:21.365500Z",
     "shell.execute_reply": "2025-05-28T12:44:21.365378Z",
     "shell.execute_reply.started": "2025-05-28T12:44:21.365364Z"
    },
    "papermill": {
     "duration": 0.006956,
     "end_time": "2025-05-28T16:36:49.133000",
     "exception": false,
     "start_time": "2025-05-28T16:36:49.126044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px;\">\n",
    "  <h2 style=\"color: red;\">Ensemble Submission Creation</h2>\n",
    "  <p>\n",
    "    <strong>Why and How:</strong><br>\n",
    "    1. We load multiple submission files, each containing predictions from different models or folds.<br>\n",
    "    2. By averaging the predictions across these files, we reduce individual model biases and variance, improving overall prediction robustness.<br>\n",
    "    3. The <code>id</code> column is taken from the first submission file assuming all files have the same order and IDs.<br>\n",
    "    4. The averaged predictions are stored in a new DataFrame, which is then saved as a combined submission file.<br>\n",
    "    5. This simple ensemble technique often leads to better performance than using a single model's predictions.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe38f970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:36:49.145615Z",
     "iopub.status.busy": "2025-05-28T16:36:49.145303Z",
     "iopub.status.idle": "2025-05-28T16:36:50.616890Z",
     "shell.execute_reply": "2025-05-28T16:36:50.615839Z"
    },
    "papermill": {
     "duration": 1.479596,
     "end_time": "2025-05-28T16:36:50.618667",
     "exception": false,
     "start_time": "2025-05-28T16:36:49.139071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/kaggle/input/my-best-sub/submission_1.csv\")\n",
    "df2 = pd.read_csv(\"/kaggle/input/my-best-sub/submission_2.csv\")\n",
    "df3 = pd.read_csv(\"/kaggle/input/my-best-sub/submission_3.csv\")\n",
    "df4 = pd.read_csv(\"/kaggle/input/my-best-sub/submission_4.csv\")\n",
    "df5 = pd.read_csv(\"/kaggle/input/my-best-sub/submission_5.csv\")\n",
    "\n",
    "ground_truth = pd.read_csv(\"/kaggle/input/playground-series-s5e5/sample_submission.csv\")  \n",
    "\n",
    "all_preds = np.stack([df['Calories'] for df in [df1, df2, df3, df4, df5]], axis=1)\n",
    "ground_truth['Calories'] = np.median(all_preds, axis=1)\n",
    "ground_truth.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a4f6e",
   "metadata": {
    "papermill": {
     "duration": 0.004603,
     "end_time": "2025-05-28T16:36:50.628233",
     "exception": false,
     "start_time": "2025-05-28T16:36:50.623630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 25px; border-radius: 10px; font-family: Verdana, sans-serif; line-height: 1.6; max-width: 700px;\">\n",
    "\n",
    "  <h2 style=\"color: red; margin-bottom: 15px;\">Project Summary & Key Highlights üöÄ</h2>\n",
    "\n",
    "  <p>\n",
    "    In this project, we predicted <strong>Calories burned</strong> using physical and activity data, combining powerful feature engineering with advanced models and ensemble techniques.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 30px;\">Feature Engineering üõ†Ô∏è</h3>\n",
    "  <ul>\n",
    "    <li>Created features like <em>BMI</em>, <em>Body_Temp_Duration</em>, and <em>Weight_Heart_Rate</em> to enhance model understanding.</li>\n",
    "    <li>Applied one-hot encoding to categorical variables for better representation.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 30px;\">AutoML Framework & Models ü§ñ</h3>\n",
    "  <p>We used AutoML to efficiently tune and select models, reducing manual effort and improving performance.</p>\n",
    "\n",
    "  <div style=\"display: flex; gap: 20px; margin-top: 10px;\">\n",
    "    <div style=\"flex: 1; background: #f0f0f0; padding: 15px; border-radius: 8px; text-align: center;\">\n",
    "      <h4>CatBoost üê±</h4>\n",
    "      <p><strong>RMSLE:</strong> 0.05930</p>\n",
    "      <p><strong>Train Time:</strong> ~45 mins (higher due to complex features and bins)</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; background: #f0f0f0; padding: 15px; border-radius: 8px; text-align: center;\">\n",
    "      <h4>LightGBM üå≤</h4>\n",
    "      <p><strong>RMSLE:</strong> 0.05937</p>\n",
    "      <p><strong>Train Time:</strong> ~35 mins (due to max_bin=750 increasing training complexity)</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; background: #f0f0f0; padding: 15px; border-radius: 8px; text-align: center;\">\n",
    "      <h4>XGBoost ‚ö°</h4>\n",
    "      <p><strong>RMSLE:</strong> 0.05925</p>\n",
    "      <p><strong>Train Time:</strong> ~40 mins (more exhaustive training)</p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 30px;\">Validation Strategy üîç</h3>\n",
    "  <ul>\n",
    "    <li>Implemented <strong>5-fold cross-validation</strong> to ensure robust performance estimates.</li>\n",
    "    <li>Used ensemble averaging to reduce variance and avoid overfitting.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 30px;\">Ensembling ü§ù</h3>\n",
    "  <p>Combined multiple model predictions by averaging, improving prediction stability and accuracy.</p>\n",
    "\n",
    "  <p style=\"margin-top: 30px;\">\n",
    "    This comprehensive approach ensures a balance of feature richness, model power, and validation rigor ‚Äî delivering reliable calorie predictions.\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787882a",
   "metadata": {
    "papermill": {
     "duration": 0.004383,
     "end_time": "2025-05-28T16:36:50.637425",
     "exception": false,
     "start_time": "2025-05-28T16:36:50.633042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 25px; border-radius: 10px; font-family: Verdana, sans-serif; max-width: 750px; line-height: 1.6;\">\n",
    "\n",
    "  <h2 style=\"color: red; margin-bottom: 15px;\">What is AutoML? ü§ñ‚ú®</h2>\n",
    "\n",
    "  <p>\n",
    "    <strong>AutoML (Automated Machine Learning)</strong> automates the process of building, training, and tuning machine learning models, making ML accessible even to non-experts. It streamlines complex steps like data preprocessing, feature engineering, model selection, and hyperparameter tuning.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 25px;\">Types of AutoML üß∞</h3>\n",
    "  <ul>\n",
    "    <li><strong>Neural Architecture Search (NAS) üß†:</strong> Automatically designs optimal neural network architectures, especially for deep learning tasks.</li>\n",
    "    <li><strong>Hyperparameter Optimization ‚öôÔ∏è:</strong> Finds the best hyperparameters for given models using methods like Bayesian optimization, grid search, or random search.</li>\n",
    "    <li><strong>Feature Engineering Automation üîß:</strong> Generates and selects the most relevant features automatically to improve model performance.</li>\n",
    "    <li><strong>Full Pipeline Automation üöÄ:</strong> Covers end-to-end workflows from data cleaning to deployment (e.g., Google AutoML, H2O Driverless AI).</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 25px;\">Where is AutoML Used? üåç</h3>\n",
    "  <ul>\n",
    "    <li>Businesses without deep ML expertise but needing predictive analytics.</li>\n",
    "    <li>Rapid prototyping and proof of concept projects.</li>\n",
    "    <li>Data scientists aiming to save time on repetitive tasks.</li>\n",
    "    <li>Large scale automated model tuning in production environments.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 25px;\">Key Benefits & KPIs üìà</h3>\n",
    "  <ul>\n",
    "    <li>‚ö° <strong>Faster model development:</strong> Cuts development time by automating repetitive tasks.</li>\n",
    "    <li>üéØ <strong>Improved accuracy:</strong> Finds better hyperparameters and model architectures.</li>\n",
    "    <li>üìä <strong>Scalability:</strong> Easily applies to diverse datasets and problem types.</li>\n",
    "    <li>üõ†Ô∏è <strong>Reduced manual errors:</strong> Automates tedious processes, reducing human mistakes.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #b22222; margin-top: 25px;\">Popular AutoML Tools & Examples üõ†Ô∏è</h3>\n",
    "  <ul>\n",
    "    <li><strong>Google Cloud AutoML:</strong> User-friendly cloud service for image, video, text, and tabular data.</li>\n",
    "    <li><strong>H2O Driverless AI:</strong> Advanced enterprise tool with strong feature engineering capabilities.</li>\n",
    "    <li><strong>Auto-sklearn:</strong> Open-source Python library built on scikit-learn, great for tabular data.</li>\n",
    "    <li><strong>FLAML:</strong> Lightweight, efficient AutoML for fast hyperparameter tuning.</li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"margin-top: 30px; font-size: 0.9em; color: #555;\">\n",
    "    For more details, check out the <a href=\"https://en.wikipedia.org/wiki/Automated_machine_learning\" target=\"_blank\" rel=\"noopener noreferrer\">AutoML Wikipedia page</a> and <a href=\"https://www.automl.org/\" target=\"_blank\" rel=\"noopener noreferrer\">automl.org</a>.\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcef24",
   "metadata": {
    "papermill": {
     "duration": 0.004798,
     "end_time": "2025-05-28T16:36:50.646855",
     "exception": false,
     "start_time": "2025-05-28T16:36:50.642057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: white; color: black; padding: 20px; border-radius: 8px; font-family: Arial, sans-serif;\">\n",
    "  <p>üéâ Thank you to everyone who reviewed this far! üéâ</p>\n",
    "  <p>üôè Thank you so much for your support and interest! üôè I am grateful to each and every one of you for taking your valuable time to review this project. I hope the information I provided was useful and everything about the project was as you expected. üöÄ</p>\n",
    "  <p>üí° If you have any questions or feedback, please feel free to let me know. üí°</p>\n",
    "  <p>üîó See you in the next project! üîó</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11893428,
     "sourceId": 91716,
     "sourceType": "competition"
    },
    {
     "datasetId": 7536911,
     "sourceId": 11983557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4809.11961,
   "end_time": "2025-05-28T16:36:53.477020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-28T15:16:44.357410",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
